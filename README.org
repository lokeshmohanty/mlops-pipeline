#+title: Setup a basic pipeline using CI/CD tools

* Introduction
** Basic MLOps Pipeline

Data Collection -> Pre-processing -> Model Training -> Model Testing -> Deployment -> Monitoring

** CI -> Continuous Integration

Automation of merging new features/changes to the main code

*Handles*:
- Formatting (=Eg=: ~black~)
- Linting    (=Eg=: ~flake8~)
- Testing    (=Eg=: ~pytest~)

** CD -> Continuous Deployment

Automation of deployment of the new version of code to production

*Handles*:
- Containerization  (=Eg=: ~docker~)
- Orchestration     (=Eg=: ~kubernetes~)
- Final Deployment  (using own-server or cloud services)

* Github Actions

*Documentation*: [[https://docs.github.com/en/actions]]

#+begin_src yaml-ts
  name: unit-test

  on: pull_request
   
  jobs:
    build:
  	name: test-pipeline
  	runs-on: ubuntu-latest

  	steps:
    	- uses: actions/checkout@v3
    	- uses: actions/setup-python@v4
      	with:
        	python-version: '3.11'

    	- name: install deps
      	run: pip install flake8 black pytest numpy tensorflow

    	- name: format
      	run: black --check src/

    	- name: lint
      	run: flake8 src/

    	- name: test
      	run: pytest src/tests/*
#+end_src

* Jenkins

*Documentation*: [[https://www.jenkins.io/doc/]] 

Installing ~jenkins~ using ~docker~.

#+begin_src shell
  docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts-jdk11
#+end_src

* Simple python app
** Data Collection

Data: [[https://keras.io/api/datasets/cifar10/]]

** Pre-processing and Model Training

#+begin_src python
  from tensorflow import keras
  from tensorflow.keras import Sequential, layers

  model_filepath = "cifar10.keras"

  (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()
  train_images = train_images.astype('float32') / 255
  test_images = test_images.astype('float32') / 255

  num_classes = 10
  train_labels = keras.utils.to_categorical(train_labels, num_classes)
  test_labels = keras.utils.to_categorical(test_labels, num_classes)

  model = Sequential()

  model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))
  model.add(layers.BatchNormalization())
  model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))
  model.add(layers.BatchNormalization())
  model.add(layers.MaxPooling2D(pool_size=(2,2)))
  model.add(layers.Dropout(0.3))

  model.add(layers.Flatten())
  model.add(layers.Dense(32, activation='relu'))
  model.add(layers.BatchNormalization())
  model.add(layers.Dropout(0.5))
  model.add(layers.Dense(num_classes, activation='softmax'))

  model.summary()

  model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

  history = model.fit(train_images, train_labels, batch_size=64, epochs=100,
                      validation_data=(test_images, test_labels))

  model.save(model_filepath)
#+end_src

** Model Testing

A simple ~pytest~ example

#+begin_src python
  def test_always_passes():
      assert True

  def test_2_equals_2():
      assert 2 == 2
#+end_src

Test model

#+begin_src python
  import numpy as np
  import tensorflow.keras as keras

  model_filepath = "cifar10.keras"

  def test_model():
      (_, _), (test_images, test_labels) = keras.datasets.cifar10.load_data()
      test_images = test_images.astype('float32') / 255
      test_labels = keras.utils.to_categorical(test_labels, 10)

      model = keras.models.load_model(model_filepath)
      predictions = np.argmax(model.predict(test_images), axis=1)

      assert predictions[predictions[0]] == 1
#+end_src

* Others
- [[Setup a virtual environment using AWS EC2][./CLOUD-AWS.org]]
